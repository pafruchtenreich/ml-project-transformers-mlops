{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0b74e5-75b3-43d7-8882-00a97b5f223d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "551be2e9-959e-4460-9a93-468a8599cd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from functools import partial\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import warnings\n",
    "import zipfile\n",
    "\n",
    "import evaluate\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import parquet\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from transformers import BertConfig, BertTokenizer\n",
    "from unidecode import unidecode\n",
    "\n",
    "from src.features.functions_preprocessing import (\n",
    "    plot_text_length_distribution,\n",
    "    preprocess_articles,\n",
    "    preprocess_summaries,\n",
    ")\n",
    "from src.features.tokenization import parallel_tokenize\n",
    "from src.models.bert import BertSummary\n",
    "from src.models.rnn_encoder_decoder import Encoder, Decoder, Seq2Seq\n",
    "from src.models.transformer import Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb4001c3-32fd-47cf-a1cf-7e092367a892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "307adead-5653-4210-ae8b-49feee29e129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104\n"
     ]
    }
   ],
   "source": [
    "def get_allowed_cpu_count():\n",
    "    # Returns the number of CPU cores available for this process.\n",
    "    try:\n",
    "        return len(os.sched_getaffinity(0))\n",
    "    except AttributeError:\n",
    "        return os.cpu_count() or 1\n",
    "\n",
    "\n",
    "cpu_count = get_allowed_cpu_count()\n",
    "print(cpu_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "083a960e-9926-4d98-be1c-138870925f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_process = max(1, cpu_count // 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb41093c-9c96-4743-868e-7615d7602ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_num_threads(n_process)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7807d217-8730-4460-a6b4-f9b3af7dae71",
   "metadata": {},
   "source": [
    "# **Kaggle dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed6cd36-482b-4138-b90e-b530d777364c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle datasets download -d sbhatti/news-summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ae2436-3b97-4c81-9f05-fd46b54ca9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile(\"news-summarization.zip\", \"r\") as zip_ref:\n",
    "    zip_ref.extractall(\"news-summarization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda220bf-ee5f-46a1-bc49-738d2433eb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_data = pd.read_csv(\"news-summarization/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab595ed-3c4a-4432-a941-adbfa7223b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c031cbd9-5d20-4232-bc5b-013f17c33161",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = random.randint(1, len(news_data))\n",
    "\n",
    "print(news_data[\"Content\"][N])\n",
    "print()\n",
    "print(news_data[\"Summary\"][N])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad02e0f3-18ac-4587-a565-eb776f902183",
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths_article = news_data[\"Content\"].str.len()\n",
    "lengths_article.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a705352d-0993-4db0-90c1-bb638cae4a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_data = news_data[\n",
    "    (lengths_article >= lengths_article.quantile(0.10))\n",
    "    & (lengths_article <= lengths_article.quantile(0.90))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685a65b8-3e3c-4d3e-bf74-dd6e0968f5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_text_length_distribution(news_data, \"Content\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b388fa01-72d3-4f19-be84-65cfb2f72616",
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths_summary = news_data[\"Summary\"].str.len()\n",
    "lengths_summary.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d9ae62-79d1-420e-aa5e-0b0f1b920add",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_data = news_data[\n",
    "    (lengths_summary >= lengths_summary.quantile(0.10))\n",
    "    & (lengths_summary <= lengths_summary.quantile(0.90))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e8d5a5-dc67-4073-867e-8cc30911eb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_data[\"Summary\"].str.len().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735ef823-ef87-4cc4-8ec1-7f4418348be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_text_length_distribution(news_data, \"Summary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ebd3fb-536d-41de-a83e-e2a320b33623",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(news_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3d071a-a9d5-45b3-8dfb-62e2d20feddf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# news_data.loc[:, \"Content\"] = preprocess_articles(\n",
    "#     news_data[\"Content\"].tolist(), n_process=n_process, batch_size=32\n",
    "# )\n",
    "# news_data.loc[:, \"Summary\"] = preprocess_summaries(\n",
    "#     news_data[\"Summary\"].tolist(), n_process=n_process, batch_size=32\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0266194d-559a-4aee-8e81-929492060739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# news_data.to_parquet(\"news_data_cleaned.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "910e907a-49bb-42f6-880b-0df87c38a441",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_data = pd.read_parquet(\"news_data_cleaned.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4606ea4-f7ab-4d51-b4ec-2f2c60e06446",
   "metadata": {},
   "source": [
    "# **Tokenization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bd31c4c-bbfa-4bb0-b3a7-4a3d28c87d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 446425\n",
      "Test size:  111607\n"
     ]
    }
   ],
   "source": [
    "data_copy = news_data[:]\n",
    "data_copy = news_data.sample(frac=1, random_state=42)\n",
    "\n",
    "train_ratio = 0.8\n",
    "train_size = int(train_ratio * len(data_copy))\n",
    "\n",
    "# Slice the dataset\n",
    "train_data = data_copy[:train_size]\n",
    "test_data = data_copy[train_size:]\n",
    "\n",
    "print(f\"Train size: {len(train_data)}\")\n",
    "print(f\"Test size:  {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9b769e-51d2-437a-9220-a8c088c6bae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing Content...\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    texts_content = list(train_data[\"Content\"])\n",
    "    print(\"Tokenizing Content...\")\n",
    "    tokenized_articles = parallel_tokenize(\n",
    "        texts_content,\n",
    "        tokenizer_name=\"bert-base-uncased\",\n",
    "        max_workers=n_process,\n",
    "        chunk_size=2000,\n",
    "        max_length=512,\n",
    "    )\n",
    "    print(\"tokenized_articles.shape =\", tokenized_articles.shape)\n",
    "    torch.save(tokenized_articles, \"tokenized_articles.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e3d607c-8677-4661-8894-5e060000d353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing Summaries...\n",
      "tokenized_summaries.shape = torch.Size([446425, 129])\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    texts_summary = list(train_data[\"Summary\"])\n",
    "    print(\"Tokenizing Summaries...\")\n",
    "    tokenized_summaries = parallel_tokenize(\n",
    "        texts_summary,\n",
    "        tokenizer_name=\"bert-base-uncased\",\n",
    "        max_workers=n_process,\n",
    "        chunk_size=2000,\n",
    "        max_length=129,\n",
    "    )\n",
    "    print(\"tokenized_summaries.shape =\", tokenized_summaries.shape)\n",
    "    torch.save(tokenized_summaries, \"tokenized_summaries.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59793caa-2cea-403e-b9e4-5760c866b197",
   "metadata": {},
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    tokenized_articles = torch.load(\"tokenized_articles.pt\")\n",
    "    tokenized_summaries = torch.load(\"tokenized_summaries.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1017c3e-aa9e-402f-aa0d-08560ba542f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_ids = tokenized_articles.long()\n",
    "summary_ids = tokenized_summaries.long()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e48ae10-ef79-46f3-9a79-8762cc67f344",
   "metadata": {},
   "source": [
    "# **RNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d376bb13-c135-459b-a93c-a25a5a2c2a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "dataset = TensorDataset(tokenized_articles, tokenized_summaries)\n",
    "dataloader = DataLoader(\n",
    "    dataset, batch_size=batch_size, num_workers=n_process, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "501bf340-239c-4ea6-8b0c-9c7fbb4a47a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8d08cbb3-2eca-4521-92f5-c8bea67de7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(\n",
    "    vocab_size=tokenizer.vocab_size,\n",
    "    embed_dim=128,\n",
    "    hidden_size=128,\n",
    "    num_layers=2,\n",
    "    dropout_prob=0.1,\n",
    ")\n",
    "decoder = Decoder(\n",
    "    vocab_size=tokenizer.vocab_size,\n",
    "    embed_dim=128,\n",
    "    hidden_size=128,\n",
    "    num_layers=2,\n",
    "    dropout_prob=0.1,\n",
    ")\n",
    "\n",
    "modelSeq2Seq = Seq2Seq(encoder, decoder, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d3b2f556-1591-44df-adfb-ea54d037cf7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Step: 0, Loss: 10.4950\n",
      "Epoch: 1, Step: 5000, Loss: 6.6238\n",
      "Epoch: 1, Step: 10000, Loss: 6.5657\n",
      "Epoch 1/5 - Average Loss: 6.6579 - Time: 24815.32s\n",
      "Epoch: 2, Step: 0, Loss: 6.4132\n",
      "Epoch: 2, Step: 5000, Loss: 6.5377\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 36\u001b[0m\n\u001b[1;32m     33\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Backward pass\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Update weights\u001b[39;00m\n\u001b[1;32m     39\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)\n",
    "optimizer = torch.optim.Adam(modelSeq2Seq.parameters(), lr=2e-4)\n",
    "\n",
    "total_start_time = time.time()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_start_time = time.time()\n",
    "\n",
    "    modelSeq2Seq.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for step, batch in enumerate(dataloader):\n",
    "        input_batch, summary_batch = batch\n",
    "        input_batch = input_batch.to(device)\n",
    "        summary_batch = summary_batch.to(device)\n",
    "\n",
    "        # Clear gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = modelSeq2Seq(\n",
    "            input_batch.long(), summary_batch, teacher_forcing_ratio=0.5\n",
    "        )\n",
    "\n",
    "        # The modelâ€™s outputs shape:\n",
    "        shifted_target = summary_batch[:, 1:]\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_fn(\n",
    "            outputs.reshape(-1, outputs.shape[-1]), shifted_target.reshape(-1)\n",
    "        )\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "\n",
    "        if step % 5000 == 0:\n",
    "            print(f\"Epoch: {epoch+1}, Step: {step}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "    # Calculate average loss for the epoch\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "\n",
    "    # Calculate epoch duration\n",
    "    epoch_end_time = time.time()\n",
    "    epoch_duration = epoch_end_time - epoch_start_time\n",
    "\n",
    "    # Print epoch stats\n",
    "    print(\n",
    "        f\"Epoch {epoch+1}/{num_epochs} - \"\n",
    "        f\"Average Loss: {avg_loss:.4f} - \"\n",
    "        f\"Time: {epoch_duration:.2f}s\"\n",
    "    )\n",
    "    torch.save(\n",
    "        modelSeq2Seq.state_dict(),\n",
    "        f\"model_weights/seq2seq_weights_{epoch+1}_epochs.pth\",\n",
    "    )\n",
    "\n",
    "total_end_time = time.time()\n",
    "total_training_time = total_end_time - total_start_time\n",
    "print(f\"Total training time: {total_training_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9e6163-0efa-4ca2-8819-9a5dcbd2115e",
   "metadata": {},
   "source": [
    "# **Transformer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "19eb018b-58a2-4b87-b6a1-0c156f3ab0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "dataset = TensorDataset(tokenized_articles, tokenized_summaries)\n",
    "dataloader = DataLoader(\n",
    "    dataset, batch_size=batch_size, num_workers=n_process, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80da4a99-6bee-46ca-ae58-6aab344da32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fcd25b8e-33b9-4d2d-949a-9cacbd6485d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelTransformer = Transformer(\n",
    "    pad_idx=0,\n",
    "    voc_size=tokenizer.vocab_size,\n",
    "    hidden_size=128,\n",
    "    n_head=8,\n",
    "    max_len=512,\n",
    "    dec_max_len=512,\n",
    "    ffn_hidden=128,\n",
    "    n_layers=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2eae5581-ad3c-4e79-ab68-accd2baf12ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Step: 0, Loss: 8.7347\n",
      "Epoch: 1, Step: 5000, Loss: 6.0884\n",
      "Epoch: 1, Step: 10000, Loss: 5.5674\n",
      "Epoch 1/25 - Average Loss: 5.8770 - Time: 4494.64s\n",
      "Epoch: 2, Step: 0, Loss: 5.5321\n",
      "Epoch: 2, Step: 5000, Loss: 5.0852\n",
      "Epoch: 2, Step: 10000, Loss: 5.0708\n",
      "Epoch 2/25 - Average Loss: 5.0969 - Time: 4484.52s\n",
      "Epoch: 3, Step: 0, Loss: 5.1591\n",
      "Epoch: 3, Step: 5000, Loss: 5.0886\n",
      "Epoch: 3, Step: 10000, Loss: 4.8430\n",
      "Epoch 3/25 - Average Loss: 4.8291 - Time: 4482.74s\n",
      "Epoch: 4, Step: 0, Loss: 4.7744\n",
      "Epoch: 4, Step: 5000, Loss: 4.4929\n",
      "Epoch: 4, Step: 10000, Loss: 4.8716\n",
      "Epoch 4/25 - Average Loss: 4.6679 - Time: 4482.84s\n",
      "Epoch: 5, Step: 0, Loss: 4.3003\n",
      "Epoch: 5, Step: 5000, Loss: 4.5971\n",
      "Epoch: 5, Step: 10000, Loss: 4.7065\n",
      "Epoch 5/25 - Average Loss: 4.5532 - Time: 4483.41s\n",
      "Epoch: 6, Step: 0, Loss: 4.5081\n",
      "Epoch: 6, Step: 5000, Loss: 4.3619\n",
      "Epoch: 6, Step: 10000, Loss: 4.5513\n",
      "Epoch 6/25 - Average Loss: 4.4645 - Time: 4483.30s\n",
      "Epoch: 7, Step: 0, Loss: 4.2583\n",
      "Epoch: 7, Step: 5000, Loss: 4.5234\n",
      "Epoch: 7, Step: 10000, Loss: 4.2795\n",
      "Epoch 7/25 - Average Loss: 4.3933 - Time: 4482.28s\n",
      "Epoch: 8, Step: 0, Loss: 4.2011\n",
      "Epoch: 8, Step: 5000, Loss: 4.2953\n",
      "Epoch: 8, Step: 10000, Loss: 4.4478\n",
      "Epoch 8/25 - Average Loss: 4.3341 - Time: 4480.23s\n",
      "Epoch: 9, Step: 0, Loss: 4.4893\n",
      "Epoch: 9, Step: 5000, Loss: 4.1224\n",
      "Epoch: 9, Step: 10000, Loss: 4.3890\n",
      "Epoch 9/25 - Average Loss: 4.2834 - Time: 4488.57s\n",
      "Epoch: 10, Step: 0, Loss: 4.2656\n",
      "Epoch: 10, Step: 5000, Loss: 4.3678\n",
      "Epoch: 10, Step: 10000, Loss: 4.2896\n",
      "Epoch 10/25 - Average Loss: 4.2398 - Time: 4480.68s\n",
      "Epoch: 11, Step: 0, Loss: 4.4669\n",
      "Epoch: 11, Step: 5000, Loss: 4.0227\n",
      "Epoch: 11, Step: 10000, Loss: 4.2158\n",
      "Epoch 11/25 - Average Loss: 4.2004 - Time: 4474.65s\n",
      "Epoch: 12, Step: 0, Loss: 4.3339\n",
      "Epoch: 12, Step: 5000, Loss: 4.4798\n",
      "Epoch: 12, Step: 10000, Loss: 3.9886\n",
      "Epoch 12/25 - Average Loss: 4.1649 - Time: 4463.10s\n",
      "Epoch: 13, Step: 0, Loss: 4.0797\n",
      "Epoch: 13, Step: 5000, Loss: 4.1452\n",
      "Epoch: 13, Step: 10000, Loss: 4.1338\n",
      "Epoch 13/25 - Average Loss: 4.1332 - Time: 4446.37s\n",
      "Epoch: 14, Step: 0, Loss: 4.0027\n",
      "Epoch: 14, Step: 5000, Loss: 4.0773\n",
      "Epoch: 14, Step: 10000, Loss: 4.2097\n",
      "Epoch 14/25 - Average Loss: 4.1047 - Time: 4446.59s\n",
      "Epoch: 15, Step: 0, Loss: 3.9117\n",
      "Epoch: 15, Step: 5000, Loss: 4.2038\n",
      "Epoch: 15, Step: 10000, Loss: 4.2076\n",
      "Epoch 15/25 - Average Loss: 4.0785 - Time: 4447.27s\n",
      "Epoch: 16, Step: 0, Loss: 3.9406\n",
      "Epoch: 16, Step: 5000, Loss: 4.0254\n",
      "Epoch: 16, Step: 10000, Loss: 4.1771\n",
      "Epoch 16/25 - Average Loss: 4.0546 - Time: 4447.98s\n",
      "Epoch: 17, Step: 0, Loss: 3.9677\n",
      "Epoch: 17, Step: 5000, Loss: 3.8044\n",
      "Epoch: 17, Step: 10000, Loss: 4.1564\n",
      "Epoch 17/25 - Average Loss: 4.0326 - Time: 4450.16s\n",
      "Epoch: 18, Step: 0, Loss: 4.1940\n",
      "Epoch: 18, Step: 5000, Loss: 3.9933\n",
      "Epoch: 18, Step: 10000, Loss: 3.8414\n",
      "Epoch 18/25 - Average Loss: 4.0122 - Time: 4462.58s\n",
      "Epoch: 19, Step: 0, Loss: 3.9953\n",
      "Epoch: 19, Step: 5000, Loss: 4.1286\n",
      "Epoch: 19, Step: 10000, Loss: 4.0238\n",
      "Epoch 19/25 - Average Loss: 3.9934 - Time: 4455.11s\n",
      "Epoch: 20, Step: 0, Loss: 3.8408\n",
      "Epoch: 20, Step: 5000, Loss: 3.8836\n",
      "Epoch: 20, Step: 10000, Loss: 3.8174\n",
      "Epoch 20/25 - Average Loss: 3.9757 - Time: 4446.28s\n",
      "Epoch: 21, Step: 0, Loss: 3.8833\n",
      "Epoch: 21, Step: 5000, Loss: 4.0922\n",
      "Epoch: 21, Step: 10000, Loss: 4.0501\n",
      "Epoch 21/25 - Average Loss: 3.9588 - Time: 4447.20s\n",
      "Epoch: 22, Step: 0, Loss: 3.8997\n",
      "Epoch: 22, Step: 5000, Loss: 3.8955\n",
      "Epoch: 22, Step: 10000, Loss: 3.8914\n",
      "Epoch 22/25 - Average Loss: 3.9430 - Time: 4445.96s\n",
      "Epoch: 23, Step: 0, Loss: 3.8392\n",
      "Epoch: 23, Step: 5000, Loss: 4.0319\n",
      "Epoch: 23, Step: 10000, Loss: 3.9230\n",
      "Epoch 23/25 - Average Loss: 3.9281 - Time: 4453.89s\n",
      "Epoch: 24, Step: 0, Loss: 3.8910\n",
      "Epoch: 24, Step: 5000, Loss: 3.8279\n",
      "Epoch: 24, Step: 10000, Loss: 4.0164\n",
      "Epoch 24/25 - Average Loss: 3.9139 - Time: 4450.36s\n",
      "Epoch: 25, Step: 0, Loss: 3.9723\n",
      "Epoch: 25, Step: 5000, Loss: 3.7874\n",
      "Epoch: 25, Step: 10000, Loss: 3.8906\n",
      "Epoch 25/25 - Average Loss: 3.9004 - Time: 4444.61s\n",
      "Total training time: 111628.48s\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 25\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)\n",
    "optimizer = torch.optim.Adam(modelTransformer.parameters(), lr=2e-4)\n",
    "modelTransformer = modelTransformer.to(device)\n",
    "\n",
    "total_start_time = time.time()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_start_time = time.time()\n",
    "\n",
    "    modelTransformer.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for step, batch in enumerate(dataloader):\n",
    "        input_batch, summary_batch = batch\n",
    "        input_batch = input_batch.to(device)\n",
    "        summary_batch = summary_batch.to(device)\n",
    "\n",
    "        # Clear gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = modelTransformer(input_batch.long(), summary_batch[:, :-1])\n",
    "\n",
    "        # Shift the target by one for the loss\n",
    "        summary_batch = summary_batch[:, 1:]\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_fn(\n",
    "            outputs.reshape(-1, outputs.shape[-1]), summary_batch.reshape(-1)\n",
    "        )\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "\n",
    "        if step % 5000 == 0:\n",
    "            print(f\"Epoch: {epoch+1}, Step: {step}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "    # Calculate average loss for the epoch\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "\n",
    "    # Calculate epoch duration\n",
    "    epoch_end_time = time.time()\n",
    "    epoch_duration = epoch_end_time - epoch_start_time\n",
    "\n",
    "    # Print epoch stats\n",
    "    print(\n",
    "        f\"Epoch {epoch+1}/{num_epochs} - \"\n",
    "        f\"Average Loss: {avg_loss:.4f} - \"\n",
    "        f\"Time: {epoch_duration:.2f}s\"\n",
    "    )\n",
    "    torch.save(\n",
    "        modelTransformer.state_dict(),\n",
    "        f\"model_weights/transformer_weights_{epoch+1}_epochs.pth\",\n",
    "    )\n",
    "\n",
    "# Calculate total training time\n",
    "total_end_time = time.time()\n",
    "total_training_time = total_end_time - total_start_time\n",
    "print(f\"Total training time: {total_training_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b074d384-280a-4e2c-9495-8d44f825e9e7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_82971/2433200847.py:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(\"model_weights/transformer_weights_25_epochs.pth\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (enc_embedding): TransformerEmbedding(\n",
       "    (tok_emb): Embedding(30522, 128, padding_idx=1)\n",
       "    (pos_emb): PositionalEncoding()\n",
       "    (drop_out): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (dec_embedding): TransformerEmbedding(\n",
       "    (tok_emb): Embedding(30522, 128, padding_idx=1)\n",
       "    (pos_emb): PositionalEncoding()\n",
       "    (drop_out): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder_layers): ModuleList(\n",
       "    (0-2): 3 x EncoderLayer(\n",
       "      (attention): AttentionLayer(\n",
       "        (w_q): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (w_k): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (w_v): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (w_o): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout1): Dropout(p=0.1, inplace=False)\n",
       "      (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout3): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (decoder_layers): ModuleList(\n",
       "    (0-2): 3 x DecoderLayer(\n",
       "      (self_attention): AttentionLayer(\n",
       "        (w_q): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (w_k): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (w_v): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (w_o): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout1): Dropout(p=0.1, inplace=False)\n",
       "      (enc_dec_attention): AttentionLayer(\n",
       "        (w_q): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (w_k): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (w_v): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (w_o): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout4): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=128, out_features=30522, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelTransformer = Transformer(\n",
    "    pad_idx=0,\n",
    "    voc_size=tokenizer.vocab_size,\n",
    "    hidden_size=128,\n",
    "    n_head=8,\n",
    "    max_len=512,\n",
    "    dec_max_len=128,\n",
    "    ffn_hidden=128,\n",
    "    n_layers=3,\n",
    ")\n",
    "modelTransformer.load_state_dict(\n",
    "    torch.load(\"model_weights/transformer_weights_25_epochs.pth\")\n",
    ")\n",
    "modelTransformer.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ebdd59-cc9d-40a4-a97c-94961d40df5f",
   "metadata": {},
   "source": [
    "# **BERT model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea203f80-b14e-4a4c-939c-d5128b8aa7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "\n",
    "dataset = TensorDataset(tokenized_articles, tokenized_summaries[:, 1:])\n",
    "dataloader = DataLoader(\n",
    "    dataset, batch_size=batch_size, num_workers=n_process, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86aa5026-2b0c-44c0-a664-49c55f96ea3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c8a157c-77fb-45ff-b45c-0ee6f73d8050",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = BertConfig(\n",
    "    hidden_size=768,\n",
    "    num_hidden_layers=12,\n",
    "    num_attention_heads=12,\n",
    "    intermediate_size=3072,\n",
    "    hidden_act=\"gelu\",\n",
    "    hidden_dropout_prob=0.1,\n",
    "    attention_probs_dropout_prob=0.1,\n",
    "    max_position_embeddings=512,\n",
    "    vocab_size=tokenizer.vocab_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8f6ff0c-9d93-44ff-9a87-ff1525ce1496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Step: 0, Loss: 10.3945\n",
      "Epoch: 1, Step: 1000, Loss: 7.4132\n",
      "Epoch: 1, Step: 2000, Loss: 7.2836\n",
      "Epoch: 1, Step: 3000, Loss: 7.3756\n",
      "Epoch: 1, Step: 4000, Loss: 7.2549\n",
      "Epoch: 1, Step: 5000, Loss: 6.9630\n",
      "Epoch: 1, Step: 6000, Loss: 6.9224\n",
      "Epoch: 1, Step: 7000, Loss: 7.1673\n",
      "Epoch: 1, Step: 8000, Loss: 7.2004\n",
      "Epoch: 1, Step: 9000, Loss: 7.1884\n",
      "Epoch: 1, Step: 10000, Loss: 6.8686\n",
      "Epoch: 1, Step: 11000, Loss: 7.0304\n",
      "Epoch: 1, Step: 12000, Loss: 7.0979\n",
      "Epoch: 1, Step: 13000, Loss: 6.9227\n",
      "Epoch: 1, Step: 14000, Loss: 6.8044\n",
      "Epoch: 1, Step: 15000, Loss: 6.7914\n",
      "Epoch: 1, Step: 16000, Loss: 6.9166\n",
      "Epoch: 1, Step: 17000, Loss: 6.7282\n",
      "Epoch: 1, Step: 18000, Loss: 6.7682\n",
      "Epoch: 1, Step: 19000, Loss: 6.8237\n",
      "Epoch: 1, Step: 20000, Loss: 6.9106\n",
      "Epoch: 1, Step: 21000, Loss: 6.9015\n",
      "Epoch: 1, Step: 22000, Loss: 6.7871\n",
      "Epoch: 1, Step: 23000, Loss: 6.6100\n",
      "Epoch: 1, Step: 24000, Loss: 6.8327\n",
      "Epoch: 1, Step: 25000, Loss: 6.6020\n",
      "Epoch: 1, Step: 26000, Loss: 6.7958\n",
      "Epoch: 1, Step: 27000, Loss: 6.6092\n",
      "Epoch: 1, Step: 28000, Loss: 6.5722\n",
      "Epoch: 1, Step: 29000, Loss: 6.7122\n",
      "Epoch: 1, Step: 30000, Loss: 6.7755\n",
      "Epoch: 1, Step: 31000, Loss: 6.6485\n",
      "Epoch: 1, Step: 32000, Loss: 6.5891\n",
      "Epoch: 1, Step: 33000, Loss: 6.6053\n",
      "Epoch: 1, Step: 34000, Loss: 6.6067\n",
      "Epoch: 1, Step: 35000, Loss: 6.7021\n",
      "Epoch: 1, Step: 36000, Loss: 6.4356\n",
      "Epoch: 1, Step: 37000, Loss: 6.5236\n",
      "Epoch: 1, Step: 38000, Loss: 6.4206\n",
      "Epoch: 1, Step: 39000, Loss: 6.5354\n",
      "Epoch: 1, Step: 40000, Loss: 6.3355\n",
      "Epoch: 1, Step: 41000, Loss: 6.6170\n",
      "Epoch: 1, Step: 42000, Loss: 6.8325\n",
      "Epoch: 1, Step: 43000, Loss: 6.3821\n",
      "Epoch: 1, Step: 44000, Loss: 6.4631\n",
      "Epoch: 1, Step: 45000, Loss: 6.1471\n",
      "Epoch: 1, Step: 46000, Loss: 6.7296\n",
      "Epoch: 1, Step: 47000, Loss: 6.3854\n",
      "Epoch: 1, Step: 48000, Loss: 6.4105\n",
      "Epoch: 1, Step: 49000, Loss: 6.4260\n",
      "Epoch: 1, Step: 50000, Loss: 6.5976\n",
      "Epoch: 1, Step: 51000, Loss: 6.6827\n",
      "Epoch: 1, Step: 52000, Loss: 6.0769\n",
      "Epoch: 1, Step: 53000, Loss: 6.7491\n",
      "Epoch: 1, Step: 54000, Loss: 6.6018\n",
      "Epoch: 1, Step: 55000, Loss: 6.3778\n",
      "Epoch 1/2 - Average Loss: 6.7430 - Time: 78969.49s\n",
      "Epoch: 2, Step: 0, Loss: 6.4754\n",
      "Epoch: 2, Step: 1000, Loss: 6.4358\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader):\n\u001b[1;32m     17\u001b[0m     input_batch, summary_batch \u001b[38;5;241m=\u001b[39m batch\n\u001b[0;32m---> 18\u001b[0m     input_batch \u001b[38;5;241m=\u001b[39m \u001b[43minput_batch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     summary_batch \u001b[38;5;241m=\u001b[39m summary_batch\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;66;03m# Clear gradients\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "modelBert = BertSummary(config)\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)\n",
    "optimizer = torch.optim.Adam(modelBert.parameters(), lr=1e-5)\n",
    "modelBert.to(device)\n",
    "\n",
    "num_epochs = 1\n",
    "\n",
    "total_start_time = time.time()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_start_time = time.time()\n",
    "\n",
    "    modelBert.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for step, batch in enumerate(dataloader):\n",
    "        input_batch, summary_batch = batch\n",
    "        input_batch = input_batch.to(device)\n",
    "        summary_batch = summary_batch.to(device)\n",
    "\n",
    "        # Clear gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = modelBert(input_batch, attention_mask=input_batch.ne(0))\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_fn(outputs.view(-1, outputs.shape[-1]), summary_batch.view(-1))\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "\n",
    "        if step % 1000 == 0:\n",
    "            print(f\"Epoch: {epoch+1}, Step: {step}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "    # Calculate average loss for the epoch\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "\n",
    "    # Measure epoch time\n",
    "    epoch_end_time = time.time()\n",
    "    epoch_duration = epoch_end_time - epoch_start_time\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch+1}/{num_epochs} - \"\n",
    "        f\"Average Loss: {avg_loss:.4f} - \"\n",
    "        f\"Time: {epoch_duration:.2f}s\"\n",
    "    )\n",
    "    torch.save(\n",
    "        modelBert.state_dict(), f\"model_weights/bert_weights_{epoch+1}_epochs.pth\"\n",
    "    )\n",
    "\n",
    "# Measure total training time\n",
    "total_end_time = time.time()\n",
    "total_training_time = total_end_time - total_start_time\n",
    "print(f\"Total training time: {total_training_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710bcc62-6e95-4c54-a99e-363d0bca518e",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelBert = BertSummary(config)\n",
    "modelBert.load_state_dict(torch.load(\"model_weights/bert_weights_1epochs.pth\"))\n",
    "modelBert.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2404b2-f088-4e07-a8fc-5134f77e2c70",
   "metadata": {},
   "source": [
    "# **Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86549c6a-cebb-4a60-adf3-c1dcc84eca85",
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge = evaluate.load(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "66294ed0-5e18-4c11-9920-b3a40d55cd49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he is instantly recognisable both from his appearance - the beard and the military fatigues - and from his first name alone : fidel .\n"
     ]
    }
   ],
   "source": [
    "input_text = news_data[\"Content\"][1000]\n",
    "summary = news_data[\"Summary\"][1000]\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9aee0d68-190b-4cfb-bc78-d5c48621efa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_input = tokenizer.encode_plus(\n",
    "    input_text,\n",
    "    max_length=512,\n",
    "    truncation=True,\n",
    "    padding=\"max_length\",\n",
    "    return_tensors=\"pt\",\n",
    ")[\"input_ids\"].long()\n",
    "\n",
    "tokenized_summary = tokenizer.encode_plus(\n",
    "    summary, max_length=128, truncation=True, padding=\"max_length\", return_tensors=\"pt\"\n",
    ")[\"input_ids\"].long()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136f553d-16ed-4b0f-a70a-cee2ef2ed239",
   "metadata": {},
   "source": [
    "## Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b19171c1-a209-4f5d-a549-5c083d9047b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuba's president has been in the midst of a \" revolutionary war \", cuba's president, fidel castro, cuba's cuba, cuba, cuba and cuba.\n"
     ]
    }
   ],
   "source": [
    "start_summary = torch.zeros((1, 128))\n",
    "start_summary[0, 0] = 101\n",
    "\n",
    "for k in range(0, 127):\n",
    "    output = modelTransformer.to(device)(\n",
    "        tokenized_input.long().to(device), start_summary.long().to(device)\n",
    "    )\n",
    "    start_summary[:, k + 1] = output.argmax(dim=-1)[:, k].detach()\n",
    "    if start_summary[:, k + 1].item() == 102:\n",
    "        break\n",
    "print(tokenizer.decode(start_summary[0].long(), skip_special_tokens=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
